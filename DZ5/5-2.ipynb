{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. На занятии мы попробовали несколько фильтров различного назначения (это размытие, устранение шумов, выделение границ и тд). Каждый алгоритм, осуществляющий фильтрацию изображения, обычно имеет несколько параметров, влияющих на результат (размер ядра и тд). И для того, чтобы понять, какое именно влияние оказывают каждый из параметров или их комбинация, может потребоваться перезапустить код много раз с разными значениями параметров, что не удобно. Поэтому в этом задании вам предлагается создать оконное приложение, отображающее результат применения того или иного фильтра (можете выбрать любой, например, Canny), интерфейс (кнопки, чек-боксы, ползунки и тд), позволяющий варьировать значения параметров фильтра и смотреть, как это влияет на результат в реальном времени (обновляя выводимое изображение). Пример реализации такого интерфейса на OpenCV можно найти здесь: https://docs.opencv.org/4.x/d9/dc8/tutorial_py_trackbar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import dearpygui.dearpygui as dpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"hong.png\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "height, width, k = image.shape\n",
    "\n",
    "def re_img(image):\n",
    "    r_channel, g_channel, b_channel = cv2.split(image)\n",
    "    r_channel = r_channel / 255\n",
    "    g_channel = g_channel / 255\n",
    "    b_channel = b_channel / 255\n",
    "    alpha_channel = np.ones(b_channel.shape, dtype=b_channel.dtype)\n",
    "    return cv2.merge((r_channel, g_channel, b_channel, alpha_channel)).reshape(-1)\n",
    "def blur(sender, app_data, user_data):\n",
    "    kernel = np.ones((app_data,app_data),np.uint8)\n",
    "    img_res = cv2.dilate(image,kernel,iterations = 2)\n",
    "    dpg.set_value(\"texture_tag\", re_img(img_res))\n",
    "def sobel(sender, app_data, user_data):\n",
    "    k_x = dpg.get_value('Sobel_x')\n",
    "    k_y = dpg.get_value('Sobel_y')\n",
    "    sobelx = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=k_x)\n",
    "    sobely = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=k_y)\n",
    "    abs_grad_x = cv2.convertScaleAbs(sobelx)\n",
    "    abs_grad_y = cv2.convertScaleAbs(sobely)\n",
    "    grad = cv2.addWeighted(abs_grad_x, 0.5, abs_grad_y, 0.5, 0)\n",
    "    dpg.set_value(\"texture_tag\", re_img(grad))\n",
    "def flip(sender, app_data, user_data):\n",
    "    M1 = dpg.get_value('M1')\n",
    "    M2 = dpg.get_value('M2')\n",
    "    M3 = dpg.get_value('M3')\n",
    "    M4 = dpg.get_value('M4')\n",
    "    M5 = dpg.get_value('M5')\n",
    "    M6 = dpg.get_value('M6')\n",
    "    M = np.float32([\n",
    "        [M1, M2, M3],\n",
    "        [M4, M5, M6]]\n",
    "    )\n",
    "    img_res = cv2.warpAffine(image, M, (int(width), int(height)))\n",
    "    dpg.set_value(\"texture_tag\", re_img(img_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpg.create_context()\n",
    "\n",
    "texture_data = re_img(image)\n",
    "# width, height, channels, data = dpg.load_image(\"starry_night.jpg\")\n",
    "# texture_data = data\n",
    "with dpg.texture_registry(show=False):\n",
    "    dpg.add_dynamic_texture(width=width, height=height, default_value=texture_data, tag=\"texture_tag\")\n",
    "\n",
    "with dpg.window(tag=\"main\"):\n",
    "    with dpg.tab_bar(tag='tab_bar'):\n",
    "        with dpg.tab(label=\"Blur\"):\n",
    "            with dpg.group(horizontal=True):\n",
    "                dpg.add_text('kernel size')\n",
    "                dpg.add_input_int(width= 100, callback=blur, default_value = 1, min_value = 1, min_clamped = True)\n",
    "        with dpg.tab(label=\"Sobel operator\"):\n",
    "            with dpg.group(horizontal=True):\n",
    "                dpg.add_text('kernel size_x')\n",
    "                dpg.add_input_int(width= 100, default_value = 1, min_value = 1, min_clamped = True,tag='Sobel_x')\n",
    "            with dpg.group(horizontal=True):\n",
    "                dpg.add_text('kernel size_y')\n",
    "                dpg.add_input_int(width= 100, default_value = 1, min_value = 1, min_clamped = True,tag='Sobel_y')\n",
    "            dpg.add_button(label=\"aplay\", callback=sobel)\n",
    "        with dpg.tab(label=\"Transform\"):\n",
    "            dpg.add_text('M transform')\n",
    "            with dpg.group(horizontal=True):\n",
    "                dpg.add_input_float(width= 100, default_value=1, tag='M1')\n",
    "                dpg.add_input_float(width= 100, tag='M2')\n",
    "                dpg.add_input_float(width= 100, tag='M3')\n",
    "            with dpg.group(horizontal=True):\n",
    "                dpg.add_input_float(width= 100, tag='M4')\n",
    "                dpg.add_input_float(width= 100, default_value=1, tag='M5')\n",
    "                dpg.add_input_float(width= 100, tag='M6')\n",
    "            dpg.add_button(label=\"aplay\", callback=flip)\n",
    "    dpg.add_image(\"texture_tag\")\n",
    "\n",
    "dpg.create_viewport(title='show_metods')\n",
    "dpg.setup_dearpygui()\n",
    "dpg.set_primary_window('main', True)\n",
    "dpg.show_viewport()\n",
    "dpg.start_dearpygui()\n",
    "dpg.destroy_context()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
